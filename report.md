# Homework1 Report
# 陳冠元 105065530

TA: try to elaborate the algorithms that you implemented and any details worth mentioned.

## In this homework2, we have used the value iteration and policy iteration to Markov Decision Processes (MDPs) with finite state and action spaces problems.<p>
 
## In the "Problem 2a: state value function", due to the properties the numerical analysis and computational issues, the different order of steps (but same outcome in logical) may produce different results, so I tried many times to get the answer to pass.

<div align=left>
<img src="https://github.com/guan-yuan/homework2-MDPs/blob/master/output/1.PNG" width = "100%" alt=""/>
</div>

## We also implement the sampling-based tabular Q-Learning to let the crawler can go further. There is some comparison between tabular Q-Learning and DQN. In this homework we assume the states and actions pairs are easy to tabulate, but if not, we may use the DQN to solve the problem.

<div align=left>
<img src="https://github.com/guan-yuan/homework2-MDPs/blob/master/output/2.PNG" width = "100%" alt=""/>
</div>
